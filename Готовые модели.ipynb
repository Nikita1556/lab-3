{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3085ec43-34bb-4afb-9515-517e0489db3e",
   "metadata": {},
   "source": [
    "## Классические алгоритмы без ансамблирования\n",
    "В этом ноутбуке вам нужно обучить модели на датасете классификации из предыдущего ноутбука и сравнить результаты. Вам будет предоставлен baseline, на основе которого вы будете доделывать предсказывающие модели. Оценка лабы будет зависеть от ROC-AUC на тестовых данных по следующим критериям:\n",
    "\\\n",
    "AUC - на тестовых данных\n",
    "- $AUC \\leq 0.75$ - 0 баллов\n",
    "- $0.75 < AUC \\leq 0.76$ - 2 балла\n",
    "- $0.76 < AUC \\leq 0.77$ - 4 балла\n",
    "- $0.77 < AUC \\leq 0.78$ - 6 баллов\n",
    "- $0.78 < AUC \\leq 0.79$ - 8 баллов\n",
    "- $AUC > 0.79$ - 10 баллов\n",
    "\n",
    "\\\n",
    "В этой работе запрещено использовать ансамбли моделей (лес, бустинги и т.д.)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07e3a2-480a-4350-868e-02679ff2aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ad31b-5c83-4366-819a-34dad4edecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных из CSV файла\n",
    "data = pd.read_csv('german.csv', sep=';')\n",
    "print(data.head())  # Вывод первых 5 строк данных для проверки\n",
    "\n",
    "# Определение признаков (X) и целевой переменной (y)\n",
    "X = data.iloc[:, 1:].to_numpy()  # Все столбцы, кроме первого, как признаки\n",
    "y = data.iloc[:, 0].to_numpy()    # Первый столбец как целевая переменная\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки (80% на обучение, 20% на тестирование)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93737ec-e5eb-4d72-8beb-5dba4d4c581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Визуализация распределения классов в обучающих данных\n",
    "plt.hist(y_train, bins=2, edgecolor='k')  # Гистограмма\n",
    "plt.xticks([0, 1])  # Метки по оси X\n",
    "plt.xlabel('Class (0: Non-Creditworthy, 1: Creditworthy)')  # Подпись оси X\n",
    "plt.ylabel('Count')  # Подпись оси Y\n",
    "plt.title('Distribution of Classes in Training Data')  # Заголовок графика\n",
    "plt.show()  # Показ графика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf0690-1d07-4026-85f2-674c5688d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и обучение модели логистической регрессии\n",
    "logistic_regression_model = LogisticRegression(max_iter=1000)  # Инициализация модели\n",
    "logistic_regression_model.fit(X_train, y_train)  # Обучение модели\n",
    "\n",
    "# Создание и обучение модели дерева решений\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)  # Инициализация модели\n",
    "decision_tree_model.fit(X_train, y_train)  # Обучение модели\n",
    "\n",
    "# Создание и обучение модели K-ближайших соседей\n",
    "knn_model = KNeighborsClassifier()  # Инициализация модели\n",
    "knn_model.fit(X_train, y_train)  # Обучение модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ebd8b0-3f81-4365-9f84-44bf50bbcbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение вероятностей предсказаний для тестовой выборки\n",
    "y_prob_logistic = logistic_regression_model.predict_proba(X_test)[:, 1]\n",
    "y_prob_decision_tree = decision_tree_model.predict_proba(X_test)[:, 1]\n",
    "y_prob_knn = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Получение предсказаний классов для тестовой выборки\n",
    "y_pred_logistic = logistic_regression_model.predict(X_test)\n",
    "y_pred_decision_tree = decision_tree_model.predict(X_test)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Оценка точности моделей\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# Оценка ROC AUC для каждой модели\n",
    "roc_auc_logistic = roc_auc_score(y_test, y_prob_logistic)\n",
    "roc_auc_decision_tree = roc_auc_score(y_test, y_prob_decision_tree)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_prob_knn)\n",
    "\n",
    "# Оценка precision и recall для каждой модели\n",
    "precision_logistic = precision_score(y_test, y_pred_logistic)\n",
    "precision_decision_tree = precision_score(y_test, y_pred_decision_tree)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "\n",
    "recall_logistic = recall_score(y_test, y_pred_logistic)\n",
    "recall_decision_tree = recall_score(y_test, y_pred_decision_tree)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "\n",
    "# Вывод результатов оценки моделей\n",
    "print(f'Accuracy of Logistic Regression: {accuracy_logistic:.2f}')\n",
    "print(f'Accuracy of Decision Tree: {accuracy_decision_tree:.2f}')\n",
    "print(f'Accuracy of K-Nearest Neighbors: {accuracy_knn:.2f}')\n",
    "print(f'ROC AUC of Logistic Regression: {roc_auc_logistic:.2f}')\n",
    "print(f'ROC AUC of Decision Tree: {roc_auc_decision_tree:.2f}')\n",
    "print(f'ROC AUC of K-Nearest Neighbors: {roc_auc_knn:.2f}')\n",
    "print(f'Precision of Logistic Regression: {precision_logistic:.2f}')\n",
    "print(f'Precision of Decision Tree: {precision_decision_tree:.2f}')\n",
    "print(f'Precision of K-Nearest Neighbors: {precision_knn:.2f}')\n",
    "print(f'Recall of Logistic Regression: {recall_logistic:.2f}')\n",
    "print(f'Recall of Decision Tree: {recall_decision_tree:.2f}')\n",
    "print(f'Recall of K-Nearest Neighbors: {recall_knn:.2f}')\n",
    "\n",
    "# Визуализация ROC-кривой для каждого классификатора\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model_name, y_prob in zip(['Logistic Regression', 'Decision Tree', 'K-Nearest Neighbors'],\n",
    "                               [y_prob_logistic, y_prob_decision_tree, y_prob_knn]):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)  # Получение значений FPR и TPR\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc_score(y_test, y_prob):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Линия случайного классификатора\n",
    "plt.xlabel('False Positive Rate')  # Подпись оси X\n",
    "plt.ylabel('True Positive Rate')  # Подпись оси Y\n",
    "plt.title('ROC Curve')  # Заголовок графика\n",
    "plt.legend()  # Легенда\n",
    "plt.show()  # Показать график\n",
    "\n",
    "# Вывод значений AUC еще раз в конце для ясности\n",
    "print(f'Final ROC AUC of Logistic Regression: {roc_auc_logistic:.2f}')\n",
    "print(f'Final ROC AUC of Decision Tree: {roc_auc_decision_tree:.2f}')\n",
    "print(f'Final ROC AUC of K-Nearest Neighbors: {roc_auc_knn:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6eb00-77fd-40dc-a3c5-35c1fe0200c0",
   "metadata": {},
   "source": [
    "## Экспериментируйте\n",
    "Для получения лучшего качества придется поэкспериментировать. Подсказка: попробуйте оптимизировать гиперпараметры модели"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
